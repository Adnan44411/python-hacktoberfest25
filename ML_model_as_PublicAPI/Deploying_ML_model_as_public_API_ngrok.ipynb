{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkI03QkCFmDF"
   },
   "source": [
    "Installing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tLUT6T9FjHG",
    "outputId": "3d919230-831c-4ea2-aba6-37cc8c896efa"
   },
   "outputs": [],
   "source": [
    "!pip install fastapi\n",
    "!pip install uvicorn\n",
    "!pip install pickle5\n",
    "!pip install pydantic\n",
    "!pip install scikit-learn\n",
    "!pip install requests\n",
    "!pip install pypi-json\n",
    "!pip install pyngrok\n",
    "!pip install nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NURTbIJlFzWR"
   },
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import pickle\n",
    "import json\n",
    "import uvicorn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyngrok import ngrok\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gw9a-r-RGS1n"
   },
   "outputs": [],
   "source": [
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fH-2Snr9HDRd"
   },
   "outputs": [],
   "source": [
    "origins = [\"*\"]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://localhost:5173\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxOQ7pUfGfv7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOUmnNOCjf2k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WW4GupKKGjCf"
   },
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import os\n",
    "\n",
    "model_path = '/content/solar_svr_model.joblib'\n",
    "assert os.path.exists(model_path), \"Model file missing!\"\n",
    "\n",
    "model_data = load(model_path)\n",
    "weather_model = model_data['model']\n",
    "scaler_X = model_data['scaler_X']  # Critical for preprocessing\n",
    "scaler_y = model_data['scaler_y']  # Critical for postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgm7t0wYGk7U"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from fastapi import FastAPI, HTTPException\n",
    "import pickle  # Added missing import\n",
    "import json\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Your input model\n",
    "class WeatherInput(BaseModel):\n",
    "    temp: float\n",
    "    humidity: float\n",
    "    dew: float\n",
    "    precip: float\n",
    "    cloudcover: float\n",
    "    solarradiation: float\n",
    "    solarenergy: float\n",
    "\n",
    "\n",
    "@app.post('/weather_prediction')\n",
    "async def predict_solar_energy(input_parameters: WeatherInput):\n",
    "    # Check if model and scalers are loaded\n",
    "    if weather_model is None or scaler_X is None or scaler_y is None:\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=\"Model or scalers not loaded properly\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # Convert input to dictionary (Pydantic V2 compatible)\n",
    "        input_dict = input_parameters.model_dump()\n",
    "\n",
    "        # Create input array in correct feature order\n",
    "        input_values = np.array([[\n",
    "            input_dict['temp'],\n",
    "            input_dict['humidity'],\n",
    "            input_dict['dew'],\n",
    "            input_dict['precip'],\n",
    "            input_dict['cloudcover'],\n",
    "            input_dict['solarradiation'],\n",
    "            input_dict['solarenergy']\n",
    "        ]])\n",
    "\n",
    "        # Scale the input features\n",
    "        input_scaled = scaler_X.transform(input_values)\n",
    "\n",
    "        # Get prediction (still scaled)\n",
    "        pred_scaled = weather_model.predict(input_scaled)\n",
    "\n",
    "        # Inverse transform to get actual KWH value\n",
    "        pred_kwh = scaler_y.inverse_transform(pred_scaled.reshape(-1, 1))\n",
    "\n",
    "        # Return properly formatted response\n",
    "        return {\n",
    "            \"prediction\": float(pred_scaled[0]),  # Scaled value (0-1)\n",
    "            \"prediction_kwh\": float(pred_kwh[0][0]),  # Actual KWH value\n",
    "            \"message\": \"Success\",\n",
    "            \"status_code\": 200\n",
    "        }\n",
    "\n",
    "    except KeyError as e:\n",
    "        raise HTTPException(\n",
    "            status_code=400,\n",
    "            detail=f\"Missing required feature: {str(e)}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=400,\n",
    "            detail=f\"Prediction error: {str(e)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmIUrS9dHGof",
    "outputId": "db5527b4-af4c-48ae-9cc8-45489ac025f5"
   },
   "outputs": [],
   "source": [
    "ngrok.set_auth_token(\"YOUR_API_(OR)_AUTH_KEY\")\n",
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print('Public URL:', ngrok_tunnel.public_url)\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRzyJBSBHG6m"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os # Import os to check if the file exists\n",
    "\n",
    "# # Assuming you have the trained model object ready\n",
    "# # For example, if it's a scikit-learn model:\n",
    "# # from sklearn.svm import SVR\n",
    "# # svr_model = SVR() # Replace with your actual trained model\n",
    "\n",
    "# # Check if the model object exists in your environment.\n",
    "# # If not, you need to retrain or load the model correctly before saving.\n",
    "# # Example of how to create a dummy model for demonstration:\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.datasets import make_regression\n",
    "# X, y = make_regression(n_samples=100, n_features=10, random_state=0)\n",
    "# # Create and train a simple SVR model for demonstration if you don't have yours\n",
    "# try:\n",
    "#     # Try to access the existing svr_model variable\n",
    "#     svr_model_to_save = svr_model\n",
    "#     print(\"Using the existing 'svr_model' variable to save.\")\n",
    "# except NameError:\n",
    "#     # If 'svr_model' variable does not exist, create a dummy one\n",
    "#     print(\"The variable 'svr_model' does not exist. Creating a dummy SVR model and saving it.\")\n",
    "#     svr_model_to_save = SVR()\n",
    "#     svr_model_to_save.fit(X, y)\n",
    "\n",
    "\n",
    "# # --- Re-saving the model using pickle ---\n",
    "# try:\n",
    "#     with open('svr_model.pkl', 'wb') as f:\n",
    "#         pickle.dump(svr_model_to_save, f)\n",
    "#     print(\"Model successfully re-saved as 'svr_model.pkl' using pickle.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error saving model with pickle: {e}\")\n",
    "\n",
    "# # --- Loading the model using pickle ---\n",
    "# try:\n",
    "#     # loading the saved model\n",
    "#     # Ensure the file exists before trying to load\n",
    "#     if os.path.exists('svr_model.pkl'):\n",
    "#         with open('svr_model.pkl', 'rb') as f:\n",
    "#             diabetes_model = pickle.load(f)\n",
    "#         print(\"Model successfully loaded from 'svr_model.pkl' using pickle.\")\n",
    "#     else:\n",
    "#         print(\"Error: 'svr_model.pkl' not found after attempting to save.\")\n",
    "# except UnpicklingError as e:\n",
    "#     print(f\"UnpicklingError occurred during load: {e}. The file might still be corrupted or not a valid pickle file.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An unexpected error occurred during load: {e}\")\n",
    "\n",
    "# # --- Alternative: Using joblib (often preferred for scikit-learn models) ---\n",
    "# # First, install joblib if you haven't already\n",
    "# # !pip install joblib\n",
    "\n",
    "# # import joblib\n",
    "\n",
    "# # # --- Re-saving the model using joblib ---\n",
    "# # try:\n",
    "# #     joblib.dump(svr_model_to_save, 'svr_model_joblib.pkl')\n",
    "# #     print(\"Model successfully re-saved as 'svr_model_joblib.pkl' using joblib.\")\n",
    "# # except Exception as e:\n",
    "# #     print(f\"Error saving model with joblib: {e}\")\n",
    "\n",
    "# # # --- Loading the model using joblib ---\n",
    "# # try:\n",
    "# #     # Ensure the file exists before trying to load\n",
    "# #     if os.path.exists('svr_model_joblib.pkl'):\n",
    "# #         diabetes_model_joblib = joblib.load('svr_model_joblib.pkl')\n",
    "# #         print(\"Model successfully loaded from 'svr_model_joblib.pkl' using joblib.\")\n",
    "# #     else:\n",
    "# #          print(\"Error: 'svr_model_joblib.pkl' not found after attempting to save.\")\n",
    "# # except Exception as e:\n",
    "# #     print(f\"Error loading model with joblib: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxryim52jabY"
   },
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# # Load saved objects\n",
    "# saved_data = joblib.load('svr_model.pkl')\n",
    "# model = saved_data['model']\n",
    "# scaler_X = saved_data['scaler_X']\n",
    "# scaler_y = saved_data['scaler_y']\n",
    "\n",
    "# def predict_kwh(temp, humidity, dew, precip, cloudcover, solarradiation, solarenergy):\n",
    "#     # 1. Scale input\n",
    "#     input_scaled = scaler_X.transform([[temp, humidity, dew, precip, cloudcover, solarradiation, solarenergy]])\n",
    "\n",
    "#     # 2. Predict\n",
    "#     pred_scaled = model.predict(input_scaled)\n",
    "\n",
    "#     # 3. Unscale prediction\n",
    "#     return scaler_y.inverse_transform(pred_scaled.reshape(-1, 1))[0][0]\n",
    "\n",
    "# # Usage\n",
    "# predict_kwh(25.5, 60.0, 18.0, 0.0, 30.0, 450.0, 1.8)  # Returns unscaled KWH prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1swnv0Oxwf8N"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
